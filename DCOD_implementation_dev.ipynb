{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "DeepDecode_Reconfigure.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "aXWRJOMULhfl"
   },
   "source": [
    "import os\r\n",
    "from getpass import getpass\r\n",
    "import urllib\r\n",
    "\r\n",
    "user = input('User name: ')\r\n",
    "password = getpass('Password: ')\r\n",
    "password = urllib.parse.quote(password)\r\n",
    "repo_name = input('Repo name: ')\r\n",
    "\r\n",
    "cmd_string = 'git clone https://{0}:{1}@github.com/{0}/{2}.git'.format(user, password, repo_name)\r\n",
    "\r\n",
    "os.system(cmd_string)\r\n",
    "cmd_string, password = \"\", \"\""
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "rDVaeXYYKc6U",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "b1eb76b0-f980-4f42-8a78-aa572bf89d08"
   },
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "hVP85D3-LVWg",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "6c167037-c8c6-4dd7-f5e4-f4c8b090c750"
   },
   "source": [
    "!pip uninstall tifffile\n",
    "!pip install imagecodecs\n",
    "!pip install imagecodecs-lite\n",
    "!pip install tifffile\n",
    "!pip install fringe\n",
    "!pip install tensorflow_addons\n",
    "\n",
    "\n",
    "project_path = '/content/drive/My Drive/git_repos/DeepDecoderNetwork'\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, project_path)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YfsYo9lPLW2I",
    "outputId": "760dbf85-720a-4588-e68d-c75f8b662a43"
   },
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import gdal\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from deep_decoder import deep_decoder\n",
    "import utils.process as p\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers as ls, activations as acts\n",
    "import tensorflow_addons as tfa\n",
    "from fringe.utils.io import import_image, import_image_seq, export_image\n",
    "from fringe.utils.modifiers import ImageToArray, PreprocessHologram, ConvertToTensor\n",
    "from fringe.process.gpu import AngularSpectrumSolver as AsSolver\n",
    "\n",
    "device = 'gpu'\n",
    "\n",
    "if device == \"gpu\":\n",
    "  if len(tf.config.experimental.list_physical_devices('GPU')) > 0:\n",
    "    print('GPU is up and running')\n",
    "    device = \"/gpu:0\"\n",
    "  else:\n",
    "    print('GPU is not available. The program will run on CPU')\n",
    "    device = \"/cpu:0\"\n",
    "elif device == \"tpu\":\n",
    "  if len(tf.config.experimental.list_physical_devices('TPU')) > 0:\n",
    "    print('TPU is up and running')\n",
    "    device = \"/tpu:0\"\n",
    "  else:\n",
    "    print('TPU is not available. The program will run on CPU')\n",
    "    device = \"/cpu:0\"\n",
    "else:\n",
    "  device = \"/cpu:0\"\n",
    "\n",
    "dtype_f = tf.float32\n",
    "dtype_c = tf.complex64"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lPjuTg4bd58P"
   },
   "source": [
    "**Cheek Cells**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "tykIh4JKLZx4"
   },
   "source": [
    "hologram_path = '/content/drive/My Drive/Colab/Dataset/Custom/cheek/2.tif'\n",
    "background_path = '/content/drive/My Drive/Colab/Dataset/Custom/background1.tif'\n",
    "\n",
    "p1 = ImageToArray(bit_depth=16, channel='gray', crop_window=[850, 1000, 512, 512], dtype='float32')\n",
    "bg = import_image(background_path, preprocessor=p1)\n",
    "p2 = PreprocessHologram(background=bg)\n",
    "p3 = ConvertToTensor(dtype=dtype_c)\n",
    "hologram = import_image(hologram_path, preprocessor=[p1, p2, p3])\n",
    "hologram_amp = tf.math.abs(hologram)\n",
    "\n",
    "solver = AsSolver(shape=hologram_amp.shape, dx=1.12, dy=1.12, wavelength=532e-3)\n",
    "z = 238 #_ 340\n",
    "\n",
    "amp = np.abs(solver.solve(hologram, z))\n",
    "#phase = unwrap_phase(np.angle(solver.solve(h, z)))\n",
    "\n",
    "'''\n",
    "w = 532.2e-3\n",
    "z = 238 #_ 340\n",
    "delta_x = 1.12\n",
    "delta_y = 1.12\n",
    "\n",
    "hologram_amp = gdal.Open(hologram_path).ReadAsArray().astype('float32')\n",
    "hologram_amp = hologram_amp[1000:1000+512,850:850+512]\n",
    "background = gdal.Open(background_path).ReadAsArray().astype('float32')\n",
    "background = background[1000:1000+512,850:850+512]\n",
    "hologram_amp /= background\n",
    "minh = np.min(hologram_amp)\n",
    "hologram_amp -= minh\n",
    "hologram_amp /= 1 - minh\n",
    "\n",
    "hologram_amp = tf.convert_to_tensor(hologram_amp, dtype_f)\n",
    "\n",
    "hologram = tf.complex(real=hologram_amp, imag=tf.zeros_like(hologram_amp)) # needs an sqrt for the amp\n",
    "\n",
    "sim = p.Simulator_TF(shape=hologram_amp.shape, delta_x=delta_x, delta_y=delta_y, wl=w, dtype_f=dtype_f, dtype_c=dtype_c)\n",
    "\n",
    "rec = sim.reconstruct(hologram, -z)\n",
    "amp = np.abs(rec)\n",
    "'''\n",
    "\n",
    "plt.imshow(hologram_amp.numpy(), cmap='gray')\n",
    "plt.show()\n",
    "plt.imshow(amp, cmap='gray')\n",
    "plt.show()\n",
    "plt.hist((hologram_amp.numpy()).flatten(), 256)\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rlwTlPaSd4Tu"
   },
   "source": [
    "**Red Blood Cells**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "aaWXOjwoLek7",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 800
    },
    "outputId": "a9e2ff48-0115-4c22-c1b3-0e2cdc3b2da9"
   },
   "source": [
    "hologram_path = '/content/drive/My Drive/Colab/Dataset/Custom/rbc/rbc_3.tif'\n",
    "background_path = '/content/drive/My Drive/Colab/Dataset/Custom/background1.tif'\n",
    "\n",
    "w = 532.2e-3\n",
    "z = 315\n",
    "delta_x = 1.12\n",
    "delta_y = 1.12\n",
    "\n",
    "hologram_amp = gdal.Open(hologram_path).ReadAsArray().astype('float32')\n",
    "hologram_amp = hologram_amp[1100:1100+512,1000:1000+512]\n",
    "background = gdal.Open(background_path).ReadAsArray().astype('float32')\n",
    "background = background[1100:1100+512,1000:1000+512]\n",
    "\n",
    "hologram_amp /= background\n",
    "minh = np.min(hologram_amp)\n",
    "hologram_amp -= minh\n",
    "hologram_amp /= 1 - minh\n",
    "\n",
    "hologram_amp = tf.convert_to_tensor(hologram_amp, dtype_f)\n",
    "\n",
    "hologram = tf.complex(real=hologram_amp, imag=tf.zeros_like(hologram_amp))\n",
    "sim = p.Simulator_TF(shape=hologram_amp.shape, delta_x=delta_x, delta_y=delta_y, wl=w, dtype_f=dtype_f, dtype_c=dtype_c)\n",
    "rec = sim.reconstruct(hologram, -z)\n",
    "\n",
    "plt.imshow(hologram_amp.numpy(), cmap='gray')\n",
    "plt.show()\n",
    "plt.hist((hologram_amp.numpy()).flatten(), 256)\n",
    "plt.show()\n",
    "\n",
    "rec = sim.reconstruct(tf.complex(hologram_amp, tf.zeros_like(hologram_amp)), z)\n",
    "plt.imshow(tf.math.abs(rec).numpy()[0:100, 100:200], cmap='gray', vmin=0, vmax=1)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EhjoZhCglJt0"
   },
   "source": [
    "**Red Blood Cells 2**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "DnvfJ02WlDaA"
   },
   "source": [
    "hologram_path = '/content/drive/My Drive/Colab/Dataset/Custom/rbc/rbc_3.tif'\n",
    "background_path = '/content/drive/My Drive/Colab/Dataset/Custom/background1.tif'\n",
    "\n",
    "w = 532.2e-3\n",
    "z = 300\n",
    "delta_x = 1.12\n",
    "delta_y = 1.12\n",
    "\n",
    "hologram_amp = gdal.Open(hologram_path).ReadAsArray().astype('float32')\n",
    "hologram_amp = hologram_amp[1200:1200+512,1500:1500+512]\n",
    "background = gdal.Open(background_path).ReadAsArray().astype('float32')\n",
    "background = background[1200:1200+512,1500:1500+512]\n",
    "hologram_amp -= 0.7*background\n",
    "hologram_amp -= np.min(hologram_amp)\n",
    "\n",
    "x, y = round(hologram_amp.shape[0]), round(hologram_amp.shape[1])\n",
    "\n",
    "hologram_amp /= np.max(hologram_amp)\n",
    "hologram_amp /= 0.2\n",
    "hologram_amp = tf.convert_to_tensor(hologram_amp, dtype_f)\n",
    "\n",
    "hologram = tf.complex(real=hologram_amp, imag=tf.zeros_like(hologram_amp))\n",
    "sim = p.Simulator_TF(shape=hologram_amp.shape, delta_x=delta_x, delta_y=delta_y, wl=w, dtype_f=dtype_f, dtype_c=dtype_c)\n",
    "rec = sim.reconstruct(hologram, -z)\n",
    "\n",
    "plt.imshow(hologram_amp.numpy(), cmap='gray')\n",
    "plt.show()\n",
    "plt.hist((hologram_amp.numpy()).flatten(), 256)\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3EQdUKsWdxf7"
   },
   "source": [
    "**Diffraction Grating**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "0lzXN4iG1EMt"
   },
   "source": [
    "hologram_path = '/content/drive/My Drive/Colab/Dataset/Custom/resolution/2.tif'\n",
    "background_path = '/content/drive/My Drive/Colab/Dataset/Custom/background.tif'\n",
    "\n",
    "w = 532.2e-3\n",
    "z = 956\n",
    "delta_x = 1.12\n",
    "delta_y = 1.12\n",
    "\n",
    "hologram_amp = gdal.Open(hologram_path).ReadAsArray().astype('float32')\n",
    "hologram_amp = hologram_amp[170:170+512,900:900+512] #[400:400+512,900:900+512]\n",
    "background = gdal.Open(background_path).ReadAsArray().astype('float32')\n",
    "background = background[170:170+512,900:900+512]\n",
    "hologram_amp -= 0.1*background\n",
    "hologram_amp -= np.min(hologram_amp)\n",
    "\n",
    "x, y = round(hologram_amp.shape[0]), round(hologram_amp.shape[1])\n",
    "\n",
    "hologram_amp /= np.max(hologram_amp)\n",
    "hologram_amp /= 0.4\n",
    "hologram_amp = tf.convert_to_tensor(hologram_amp, dtype_f)\n",
    "\n",
    "hologram = tf.complex(real=hologram_amp, imag=tf.zeros_like(hologram_amp))\n",
    "sim = p.Simulator_TF(shape=hologram_amp.shape, delta_x=delta_x, delta_y=delta_y, wl=w, dtype_f=dtype_f, dtype_c=dtype_c)\n",
    "rec = sim.reconstruct(hologram, -z)\n",
    "\n",
    "plt.imshow(hologram_amp.numpy(), cmap='gray')\n",
    "plt.show()\n",
    "plt.hist((hologram_amp.numpy()).flatten(), 256)\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zHKVaqoSds2P"
   },
   "source": [
    "**USAF 1951 Target**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "b8bvlOGBFJLB"
   },
   "source": [
    "hologram_path = '/content/drive/My Drive/Colab/Dataset/Custom/resolution/1.tif'\n",
    "background_path = '/content/drive/My Drive/Colab/Dataset/Custom/background2.tif'\n",
    "\n",
    "w = 532.2e-3\n",
    "z = 1065\n",
    "delta_x = 1.12\n",
    "delta_y = 1.12\n",
    "\n",
    "hologram_amp = gdal.Open(hologram_path).ReadAsArray().astype('float32')\n",
    "hologram_amp = hologram_amp[180:180+512,190:190+512]\n",
    "#background = gdal.Open(background_path).ReadAsArray().astype('float32')\n",
    "#background = background[570:570+512,900:900+512]\n",
    "#hologram_amp -= 0.1*background\n",
    "#hologram_amp -= np.min(hologram_amp)\n",
    "\n",
    "x, y = round(hologram_amp.shape[0]), round(hologram_amp.shape[1])\n",
    "\n",
    "hologram_amp /= np.max(hologram_amp)\n",
    "hologram_amp /= 0.4\n",
    "hologram_amp = tf.convert_to_tensor(hologram_amp, dtype_f)\n",
    "\n",
    "hologram = tf.complex(real=hologram_amp, imag=tf.zeros_like(hologram_amp))\n",
    "sim = p.Simulator_TF(shape=hologram_amp.shape, delta_x=delta_x, delta_y=delta_y, wl=w, dtype_f=dtype_f, dtype_c=dtype_c)\n",
    "rec = sim.reconstruct(hologram, -z)\n",
    "\n",
    "plt.imshow(hologram_amp.numpy(), cmap='gray')\n",
    "plt.show()\n",
    "plt.hist((hologram_amp.numpy()).flatten(), 256)\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L1sQyTqndnFG"
   },
   "source": [
    "**Simulation 1**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "lpB8mSPuLgoV"
   },
   "source": [
    "from skimage.filters import gaussian\n",
    "\n",
    "amp_path = '/content/drive/My Drive/Colab/Dataset/Custom/tests/baboon.png'\n",
    "#amp_path = '/content/drive/My Drive/Colab/Dataset/Custom/tests/cameraman.png'\n",
    "ph_path = '/content/drive/My Drive/Colab/Dataset/Custom/tests/peppers.png'\n",
    "\n",
    "w = 532.2e-3\n",
    "z = 300\n",
    "delta_x = 1.12\n",
    "delta_y = 1.12\n",
    "\n",
    "amp = np.array(Image.open(amp_path).convert(\"L\")).astype('float32')\n",
    "ph = np.array(Image.open(ph_path).convert(\"L\")).astype('float32')\n",
    "\n",
    "\n",
    "perc = 1\n",
    "amp /= np.max(amp)\n",
    "amp += 1/perc - 1\n",
    "amp /= np.max(amp)\n",
    "#amp = np.ones(ph.shape) ###########################\n",
    "\n",
    "sigma = 0#np.exp(3)\n",
    "amp = gaussian(amp, sigma, mode='reflect', truncate=10)\n",
    "\n",
    "ph /= np.max(ph)\n",
    "ph *= 2 * np.pi - 0.2 * np.pi\n",
    "ph -= np.pi\n",
    "\n",
    "obj_func = tf.convert_to_tensor(amp * np.exp(1j * ph), dtype_c)\n",
    "\n",
    "sim = p.Simulator_TF(shape=amp.shape, delta_x=delta_x, delta_y=delta_y, wl=w, dtype_f=dtype_f, dtype_c=dtype_c)\n",
    "hologram_amp = tf.math.abs(sim.reconstruct(obj_func, z))\n",
    "hologram_amp = tf.math.pow(hologram_amp, 2)\n",
    "\n",
    "\n",
    "plt.imshow(tf.math.abs(obj_func).numpy(), cmap='gray', vmin=0, vmax=1)\n",
    "plt.show()\n",
    "plt.imshow(tf.math.angle(obj_func).numpy(), cmap='viridis')\n",
    "plt.show()\n",
    "plt.imshow(hologram_amp.numpy(), cmap='gray')\n",
    "plt.show()\n",
    "plt.hist((hologram_amp.numpy()).flatten(), 256)\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JrGe5EzyL4fN",
    "outputId": "84ed4143-8275-4792-b126-6c62a666bcda"
   },
   "source": [
    "#Analysis\n",
    "from numpy.fft import fft2\n",
    "\n",
    "def RMS(img):\n",
    "    return np.sqrt(np.mean(np.square(img)))\n",
    "\n",
    "def PSD(img):\n",
    "    fft = fft2(img)\n",
    "\n",
    "\n",
    "print(RMS(hologram_amp.numpy()**2))\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q2wd9GSZdYlU"
   },
   "source": [
    "**Simulation 2: Multiple planes**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5Va_DRYrTNem"
   },
   "source": [
    "ph1_path = '/content/drive/My Drive/Colab/Dataset/Custom/tests/baboon.png'\n",
    "ph2_path = '/content/drive/My Drive/Colab/Dataset/Custom/tests/peppers.png'\n",
    "\n",
    "w = 532.2e-3\n",
    "z1 = 300\n",
    "z2 = z1 + 100\n",
    "delta_x = 1.12\n",
    "delta_y = 1.12\n",
    "\n",
    "ph1 = np.array(Image.open(ph1_path).convert(\"L\")).astype('float32')\n",
    "ph2 = np.array(Image.open(ph2_path).convert(\"L\")).astype('float32')\n",
    "\n",
    "amp1 = np.ones(ph1.shape)\n",
    "ph1 /= np.max(ph1)\n",
    "ph1 *= 2 * np.pi\n",
    "ph1 -= np.pi\n",
    "\n",
    "obj_func1 = tf.convert_to_tensor(amp1 * np.exp(1j * ph1), dtype_c)\n",
    "\n",
    "\n",
    "amp2 = np.ones(ph2.shape)\n",
    "ph2 /= np.max(ph2)\n",
    "ph2 *= 2 * np.pi\n",
    "ph2 -= np.pi\n",
    "\n",
    "obj_func2 = tf.convert_to_tensor(amp2 * np.exp(1j * ph2), dtype_c)\n",
    "\n",
    "\n",
    "sim = p.Simulator_TF(shape=ph1.shape, delta_x=delta_x, delta_y=delta_y, wl=w, dtype_f=dtype_f, dtype_c=dtype_c)\n",
    "hologram1 = sim.reconstruct(obj_func1, z1)\n",
    "hologram2 = sim.reconstruct(obj_func2, z2)\n",
    "hologram_amp = tf.math.abs(hologram1/2 + hologram2/2)\n",
    "hologram_amp = tf.math.pow(hologram_amp, 2)\n",
    "\n",
    "\n",
    "plt.imshow(tf.math.abs(obj_func2).numpy(), cmap='gray', vmin=0, vmax=1)\n",
    "plt.show()\n",
    "plt.imshow(tf.math.angle(obj_func2).numpy(), cmap='viridis', vmin=-np.pi, vmax=np.pi)\n",
    "plt.show()\n",
    "plt.imshow(hologram_amp.numpy(), cmap='gray')\n",
    "plt.show()\n",
    "plt.hist((hologram_amp.numpy()).flatten(), 256)\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-HAVUtqELiWz"
   },
   "source": [
    "def gini(mat):\n",
    "  n = mat.shape[0] * mat.shape[1]\n",
    "  indices = np.arange(1, n + 1).reshape(mat.shape[0], mat.shape[1])\n",
    "  mat[mat < 0] = 0\n",
    "  mat += 1e-8\n",
    "  return np.sum((2 * indices - n  - 1) * mat) / (n * np.sum(mat))\n",
    "\n",
    "\n",
    "def grad_contrast_estimate(hologram, kernel_r, kernel_i, kernel1_r, kernel1_i):\n",
    "  grad = hologram\n",
    "  grad_r = tf.nn.conv2d(tf.math.real(grad), kernel_r, padding='VALID', strides=1) \n",
    "  grad_r = -tf.nn.conv2d(tf.math.imag(grad), kernel_i, padding='VALID', strides=1) + grad_r\n",
    "  grad_i = tf.nn.conv2d(tf.math.real(grad), kernel_i, padding='VALID', strides=1)\n",
    "  grad_i = tf.nn.conv2d(tf.math.imag(grad), kernel_r, padding='VALID', strides=1) + grad_i\n",
    "\n",
    "  grad = tf.complex(grad_r, grad_i)\n",
    "\n",
    "  grad_r = tf.nn.conv2d(tf.math.real(grad), kernel1_r, padding='VALID', strides=1) \n",
    "  grad_r = -tf.nn.conv2d(tf.math.imag(grad), kernel1_i, padding='VALID', strides=1) + grad_r\n",
    "  grad_i = tf.nn.conv2d(tf.math.real(grad), kernel1_i, padding='VALID', strides=1)\n",
    "  grad_i = tf.nn.conv2d(tf.math.imag(grad), kernel1_r, padding='VALID', strides=1) + grad_i\n",
    "\n",
    "  grad = tf.squeeze(tf.complex(grad_r, grad_i))\n",
    "\n",
    "  grad_abs = tf.math.abs(grad)\n",
    "  grad_abs -= tf.reduce_min(grad_abs)\n",
    "  grad_abs /= tf.reduce_max(grad_abs)\n",
    "\n",
    "  return grad_abs, tf.math.reduce_std(grad_abs)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "mlO_GQ2BLkDQ"
   },
   "source": [
    "#coefs= []\n",
    "#zs = []\n",
    "for z_ in np.linspace(300, 400, 100):\n",
    "  rec = tf.expand_dims(tf.expand_dims(sim.reconstruct(tf.complex(hologram_amp, tf.zeros_like(hologram_amp)), z_), 0), -1)\n",
    "  #grad_abs, std = grad_contrast_estimate(rec, kernel_r, kernel_i, kernel1_r, kernel1_i)\n",
    "  #coefs.append(std)\n",
    "  #zs.append(z_)\n",
    "\n",
    "  print(z_)#, std)\n",
    "  #plt.imshow(grad_abs, cmap='gray')\n",
    "  plt.imshow(tf.squeeze(tf.math.abs(rec)).numpy()[0:100, 100:200], cmap='gray')\n",
    "  plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "J0KGNRqWt32g"
   },
   "source": [
    "rec = sim.reconstruct(tf.complex(hologram_amp, tf.zeros_like(hologram_amp)), -z+20)\n",
    "plt.imshow(tf.math.abs(rec).numpy()[0:100, 200:300], cmap='gray')\n",
    "plt.show()\n",
    "print(z)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "hwxJjrvqLlxl"
   },
   "source": [
    "print(np.argmax(coefs))\n",
    "plt.plot(zs, coefs)\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "CT2I3ViaLm6I"
   },
   "source": [
    "steps = 100\n",
    "min = 300.0\n",
    "max = 400.0\n",
    "focus = 238\n",
    "\n",
    "s = (max - min) / steps\n",
    "\n",
    "x = np.arange(0, steps, 1).astype('float')\n",
    "mu = (focus - min) / s\n",
    "b = 0.5\n",
    "\n",
    "std_true = (1/(2*b)) * np.exp(-np.abs(x - mu)/b)\n",
    "std_true /= np.max(std_true)\n",
    "std_true *= 3\n",
    "std_true += 1\n",
    "\n",
    "plt.plot(std_true)\n",
    "\n",
    "std_true = tf.convert_to_tensor(std_true)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "UKmTrikmLoTh"
   },
   "source": [
    "kernel1 = np.array([[ -3-3j, 0-10j,  +3 -3j],\n",
    "                   [-10+0j, 0+ 0j, +10 +0j],\n",
    "                   [ -3+3j, 0+10j,  +3 +3j]])\n",
    "\n",
    "\n",
    "kernel2 = np.array([[ -0.7-0.7j, -1-0j,  -0.7-0.7j],\n",
    "                   [-0-1j, 16+ 0j, -0-1j],\n",
    "                   [ -0.7-0.7j, -1-0j,  -0.7-0.7j]])"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "V-Tgql9kLpyw"
   },
   "source": [
    "kernel_r = np.array([[-2.5839245,   1.22572,     3.090602  ],\n",
    "                    [-9.775546,    0.06834003,  9.433271  ],\n",
    "                    [-2.8582098,  -0.35271487,  2.649898  ]])\n",
    "\n",
    "\n",
    "kernel_i = np.array([[ -4.323572,   -10.040517,    -4.5209517 ],\n",
    "                    [  1.5261726,    0.4911819,    0.04328072],\n",
    "                    [  4.0507317,    9.479661,     3.2323513 ]])\n",
    "\n",
    "\n",
    "kernel1_r = np.array([[-2.7445161,  -1.1729007,  -0.06390718],\n",
    "                     [-1.6279972,  11.676395,   -0.57471746],\n",
    "                     [ 1.0288606,  -2.2464204,   0.53905797]])\n",
    "\n",
    "\n",
    "kernel1_i = np.array([[-2.169251,    0.02520088,  2.2947078 ],\n",
    "                      [-0.818566,    1.5841165,   0.48902965],\n",
    "                      [-1.9705292,  -3.985643,   -1.9151871 ]])\n",
    "\n",
    "kernel1 = tf.complex(kernel_r, kernel_i)\n",
    "kernel2 = tf.complex(kernel1_r, kernel1_i)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "w0bsgVe9LrmL"
   },
   "source": [
    "kernel_r = tf.Variable(tf.expand_dims(tf.expand_dims(tf.cast(tf.math.real(kernel1), dtype='float32'), -1), -1), dtype='float32', trainable=True)\n",
    "kernel_i = tf.Variable(tf.expand_dims(tf.expand_dims(tf.cast(tf.math.imag(kernel1), dtype='float32'), -1), -1), dtype='float32', trainable=True)\n",
    "kernel1_r = tf.Variable(tf.expand_dims(tf.expand_dims(tf.cast(tf.math.real(kernel2), dtype='float32'), -1), -1), dtype='float32', trainable=True)\n",
    "kernel1_i = tf.Variable(tf.expand_dims(tf.expand_dims(tf.cast(tf.math.imag(kernel2), dtype='float32'), -1), -1), dtype='float32', trainable=True)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "IJOZdF__Lszd"
   },
   "source": [
    "trainable_variables = [kernel_r, kernel_i, kernel1_r, kernel1_i]\n",
    "\n",
    "optimizer = tf.optimizers.Adam(learning_rate=0.01)\n",
    "mse = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "epochs = 500\n",
    "for i in range(epochs):\n",
    "  with tf.GradientTape() as tape:\n",
    "    \n",
    "    k = 0\n",
    "    std_tensor = tf.zeros_like(std_true, dtype=dtype_f)\n",
    "    std_shape = std_tensor.shape\n",
    "    for z_ in np.linspace(100, 300, 100):\n",
    "      rec = tf.expand_dims(tf.expand_dims(sim.reconstruct(hologram, z_), 0), -1)\n",
    "      grad_abs, std = grad_contrast_estimate(rec, kernel_r, kernel_i, kernel1_r, kernel1_i)\n",
    "\n",
    "      index = [[k, ]]\n",
    "      value = [std]\n",
    "      delta = tf.SparseTensor(index, value, std_shape)\n",
    "      std_tensor += tf.sparse.to_dense(delta)\n",
    "      \n",
    "      #if k % 20 == 0:\n",
    "      #  print(k)\n",
    "      k += 1\n",
    "\n",
    "    std_tensor /= tf.reduce_mean(grad_abs)\n",
    "    loss = mse(std_tensor, std_true)\n",
    "\n",
    "  grads = tape.gradient(loss, trainable_variables)\n",
    "  optimizer.apply_gradients(zip(grads, trainable_variables))\n",
    "\n",
    "  plt.plot(std_tensor)\n",
    "  plt.show()\n",
    "  print(\"Epoch {:03d}: Loss: {:.6f}\".format(i, loss.numpy()), np.argmax(std_tensor.numpy()))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "AOa8RF4RLuSs"
   },
   "source": [
    "print(kernel_r.numpy().reshape([3,3]))\n",
    "print(kernel_i.numpy().reshape([3,3]))\n",
    "print(kernel1_r.numpy().reshape([3,3]))\n",
    "print(kernel1_i.numpy().reshape([3,3]))\n",
    "plt.imshow(kernel1_r.numpy().reshape([3,3]))\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZTA7WTVMRUwW"
   },
   "source": [
    "Training Sequence"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "pK0IXdfTZWlj"
   },
   "source": [
    "def export_images(step):\n",
    "    out = net1(input_t)\n",
    "    out = tf.squeeze(out)\n",
    "\n",
    "    _ph = out[...,0].numpy()\n",
    "    _amp = out[...,1].numpy()\n",
    "\n",
    "    out_ph = np.uint8(_ph * 255)\n",
    "    out_ph = Image.fromarray(out_ph)\n",
    "    out_ph = out_ph.convert('L')\n",
    "    out_ph.save(os.path.join(log_root, 'exports', 'out_phase_{:d}.png'.format(int(checkpoint.step))))\n",
    "\n",
    "    cmap = matplotlib.cm.get_cmap('viridis')\n",
    "    out_ph = cmap(_ph.copy())\n",
    "    out_ph = np.uint8(out_ph * 255)\n",
    "    out_ph = Image.fromarray(out_ph)\n",
    "    out_ph = out_ph.convert('RGB')\n",
    "    out_ph.save(os.path.join(log_root, 'exports', 'out_phase_c_{:d}.png'.format(int(checkpoint.step))))\n",
    "\n",
    "    out_amp = np.uint8(_amp * 255)\n",
    "    out_amp = Image.fromarray(out_amp)\n",
    "    out_amp = out_amp.convert('L')\n",
    "    out_amp.save(os.path.join(log_root, 'exports', 'out_amp_{:d}.png'.format(int(checkpoint.step))))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TiuQ_3PfLvqZ",
    "outputId": "08c011a8-e57c-40c3-91a7-00043472ddff"
   },
   "source": [
    "num_epochs = 30000\n",
    "lr = tf.Variable(0.01, dtype=dtype_f)\n",
    "weight_decay = tf.Variable(0.002, dtype=dtype_f)\n",
    "\n",
    "\n",
    "def get_lr():\n",
    "\treturn lr.numpy()\n",
    " \n",
    "def get_wd():\n",
    "\treturn weight_decay.numpy()\n",
    "\n",
    "random_seed = 999\n",
    "print(\"Random Seed: \", random_seed)\n",
    "random.seed(random_seed)\n",
    "tf.random.set_seed(random_seed)\n",
    "\n",
    "input_t_ref = tf.random.normal([1, 16, 16, 256], mean=0, stddev=0.1, dtype=dtype_f)\n",
    "input_t = tf.Variable(input_t_ref)\n",
    "\n",
    "net1 = deep_decoder(input_shape=input_t[0].shape,\n",
    "\t\t\t\t\t layers_channels=[256, 256, 256, 256, 256],\n",
    "\t\t\t\t\t kernel_sizes=[1]*5,\n",
    "\t\t\t\t\t out_channels=2,\n",
    "\t\t\t\t\t upsample_mode='bilinear',\n",
    "\t\t\t\t\t activation_func=ls.ReLU(),\n",
    "\t\t\t\t\t #activation_func=ls.LeakyReLU(0.1),\n",
    "\t\t\t\t\t out_activation=acts.sigmoid,\n",
    "\t\t\t\t\t #out_activation=acts.hard_sigmoid,\n",
    "\t\t\t\t\t #out_activation=ls.ReLU(),\n",
    "\t\t\t\t\t #out_activation=None,\n",
    "\t\t\t\t\t bn_affine=True)\n",
    "\n",
    "#################################\n",
    "\n",
    "#optimizer = tf.keras.optimizers.Adamax(learning_rate=get_lr)\n",
    "optimizer = tfa.optimizers.AdamW(learning_rate=get_lr, weight_decay=get_wd)\n",
    "mse = tf.keras.losses.MeanSquaredError()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "g4Pulfx2f039"
   },
   "source": [
    "net1.summary()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 366
    },
    "id": "nv_gceoZLxTH",
    "outputId": "7828ffcc-cb8a-4f1d-d2d7-99a9757fef96"
   },
   "source": [
    "logs_path = '/content/drive/My Drive/Colab/Logs'\n",
    "log_folder = 'log_107_cheekcells_AdamWR_ddn'\n",
    "\n",
    "log_root = os.path.join(logs_path, log_folder)\n",
    "if not os.path.exists(log_root):\n",
    "    os.mkdir(log_root)\n",
    "\n",
    "if not os.path.exists(os.path.join(log_root, 'exports')):\n",
    "    os.mkdir(os.path.join(log_root, 'exports'))\n",
    "\n",
    "#amp_coefs = [1.2, 1.1, 1.2, 1.1, 1.2, 1.1, 1.15, 1.1, 1.15, 1.1]\n",
    "amp_coefs = [1.3, 1.4]\n",
    "amp_coef = tf.Variable(amp_coefs[0], dtype=dtype_f)\n",
    "amp_rand_std = tf.Variable(0.02, dtype=dtype_f)\n",
    "\n",
    "checkpoint_folder = 'ckpts'\n",
    "checkpoint = tf.train.Checkpoint(step=tf.Variable(0),\n",
    "                                 optimizer=optimizer,\n",
    "                                 model=net1,\n",
    "                                 input_t=input_t,\n",
    "                                 amp_coef=amp_coef,\n",
    "                                 amp_rand_std=amp_rand_std,\n",
    "                                 lr=lr,\n",
    "                                 wd=weight_decay)\n",
    "manager = tf.train.CheckpointManager(checkpoint, os.path.join(log_root, checkpoint_folder), max_to_keep=20)\n",
    "checkpoint.restore(manager.latest_checkpoint)\n",
    "\n",
    "save_interval = 5000\n",
    "amp_coefs_interval = 500\n",
    "last_log = int(checkpoint.step)\n",
    "start_epoch = int(checkpoint.step)\n",
    "\n",
    "if checkpoint.step.numpy() != 0:\n",
    "    print('Continuing training from step:', checkpoint.step.numpy())\n",
    "else: \n",
    "    print('Initializing model checkpoints')\n",
    "\n",
    "log_array = np.zeros((save_interval, 3), dtype='float32')\n",
    "\n",
    "log_name = 'log.csv'\n",
    "if os.path.exists(os.path.join(log_root, log_name)):\n",
    "    log = pd.read_csv(os.path.join(log_root, log_name), index_col=0)\n",
    "    log.drop(log.index[int(checkpoint.step):], inplace=True)\n",
    "    loss_list = log['loss'].tolist()[-100:]\n",
    "else:\n",
    "    log = pd.DataFrame(columns=['epoch', 'loss', 'loss_avg'], )\n",
    "    loss_list = []\n",
    "\n",
    "if int(checkpoint.step) >= save_interval-1:\n",
    "    print('\\nparameters:')\n",
    "    print('- learning rate:', checkpoint.lr.numpy())\n",
    "    print('- weight decay:', checkpoint.wd.numpy())\n",
    "    print('- amp coefficient:', checkpoint.amp_coef.numpy())\n",
    "\n",
    "    plt.plot(log['loss_avg'])\n",
    "    plt.yscale('log')\n",
    "    plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "8_IdlImmNgDe",
    "outputId": "afd73f2f-7ec3-47e0-a029-edbc4c6caf3a"
   },
   "source": [
    "#%%time\n",
    "random_init = True\n",
    "random_amp = True\n",
    "''''''\n",
    "lr.assign(0.01)\n",
    "weight_decay.assign(0.002)\n",
    "amp_rand_std.assign(0.02)\n",
    "amp_coefs = [1.3, 1.4]\n",
    "amp_coefs_interval = 500\n",
    "num_epochs = 30000\n",
    "trainable_variables = net1.trainable_variables\n",
    "\n",
    "#phase_normalizer_matrix = np.zeros_like(hologram_amp)\n",
    "#phase_normalizer_matrix[0:5, 0:5] = 10\n",
    "#phase_normalizer_matrix[-5:-1, -5:-1] = -10\n",
    "#phase_normalizer_matrix = tf.convert_to_tensor(phase_normalizer_matrix)\n",
    "\n",
    "for epoch in range(int(checkpoint.step), num_epochs):\n",
    "\n",
    "    ###############################################################\n",
    "    '''alpha = 1/(0.0001 * epoch + 1)\n",
    "    weight_decay.assign(0.002 * alpha)\n",
    "    lr.assign(0.01 * alpha)\n",
    "    amp_rand_std.assign(0.01 * alpha)\n",
    "    amp_coefs[0] = 1.05 + 0.3 * alpha\n",
    "    amp_coefs[1] = amp_coefs[0] + 0.1 * alpha\n",
    "    amp_coefs_interval = round(500 * alpha)'''\n",
    "    ###############################################################\n",
    "\n",
    "    with tf.device(device):\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "\n",
    "            if (random_init or random_amp) and epoch % amp_coefs_interval == 0 and epoch != start_epoch:\n",
    "                print(\"Randomizing on step: {}\".format(epoch))\n",
    "\n",
    "                if random_init:\n",
    "                    input_t.assign(input_t_ref + tf.random.normal(input_t_ref.shape, mean=0, stddev=amp_rand_std.numpy(), dtype=dtype_f))\n",
    "                    print(\"Adding noise to the initiallizer\")\n",
    "\n",
    "                if random_amp:\n",
    "                    amp_coef_idx = (epoch % (len(amp_coefs) * amp_coefs_interval)) // amp_coefs_interval\n",
    "                    amp_coef.assign(amp_coefs[amp_coef_idx])\n",
    "                    print(\"New amp coef: \", amp_coef.numpy())\n",
    "\n",
    "            out = net1(input_t, training=True)\n",
    "            out = tf.squeeze(out)\n",
    "\n",
    "            out_ph = out[...,0]\n",
    "            #out_ph += phase_normalizer_matrix   ################################\n",
    "            #out_ph = tf.clip_by_value(out_ph, 0, 1)   ##########################\n",
    "            out_ph = tf.scalar_mul(2 * np.pi, out_ph)\n",
    "            out_ph = tf.complex(real=tf.zeros_like(out_ph), imag=out_ph)\n",
    "            out_amp = out[...,1]\n",
    "            out_amp = tf.scalar_mul(amp_coef, out_amp)\n",
    "\n",
    "            out_amp = tf.complex(real=out_amp, imag=tf.zeros_like(out_amp))\n",
    "            out_func = tf.multiply(out_amp, tf.math.exp(out_ph))\n",
    "\n",
    "            #out_hol = sim.reconstruct(out_func, z)\n",
    "            out_hol = solver.solve(out_func, z)\n",
    "            out_hol_amp = tf.math.pow(tf.math.abs(out_hol), 2)\n",
    "\n",
    "            loss_value = mse(out_hol_amp, hologram_amp)\n",
    "\n",
    "            loss_list.append(loss_value.numpy())\n",
    "            if len(loss_list) > 100:\n",
    "                loss_list.pop(0)\n",
    "            loss_avg = np.mean(np.array(loss_list))\n",
    "\n",
    "        grads = tape.gradient(loss_value, trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, trainable_variables))\n",
    "\n",
    "        if epoch % 20 == 0:\n",
    "            print(\"Epoch {:03d}: Loss: {:.5f} Loss Avg: {:.5f}\".format(epoch, loss_value, loss_avg))\n",
    "        if epoch % 100 == 0:\n",
    "            plt.imshow(out[...,0].numpy())\n",
    "            plt.show()\n",
    "            plt.imshow(out[...,1].numpy())\n",
    "            plt.show()\n",
    "\n",
    "        if (epoch + 1) % save_interval == 0 and epoch != start_epoch:\n",
    "            export_images(epoch)\n",
    "            save_path = manager.save()\n",
    "            print(\"Saved checkpoint for step: {}\".format(epoch))\n",
    "\n",
    "        if (epoch % save_interval == 0 and epoch != start_epoch) or epoch == num_epochs - 1:\n",
    "            save_path = manager.save()\n",
    "            print(\"Saved checkpoint for step: {}\".format(epoch))\n",
    "            log_array = log_array[log_array[:,1] != 0, :]\n",
    "            log = pd.concat([log, pd.DataFrame(log_array, columns=['epoch', 'loss', 'loss_avg'])], sort=False, axis=0, ignore_index=True)\n",
    "            log.to_csv(os.path.join(log_root, log_name), header=True, columns=['epoch', 'loss', 'loss_avg'])\n",
    "            log_array = np.zeros((save_interval, 3), dtype='float32')\n",
    "            last_log = epoch\n",
    "        \n",
    "        log_array[epoch - last_log] = [epoch, loss_value.numpy(), loss_avg]\n",
    "\n",
    "        checkpoint.step.assign_add(1)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "sMg9icLaX7Jc"
   },
   "source": [
    "#save_path = manager.save()\n",
    "#print(\"Saved checkpoint for step: {}\".format(epoch))\n",
    "\n",
    "export_images(epoch)\n",
    "\n",
    "#log = pd.concat([log, pd.DataFrame(log_array, index=log_array[:,0], columns=['epoch', 'loss', 'loss_avg'])], sort=False, axis=0, ignore_index=True)\n",
    "#log.to_csv(os.path.join(log_root, log_name), header=True, columns=['epoch', 'loss', 'loss_avg'])\n",
    "#log_array = np.zeros((save_interval, 3), dtype='float32')\n",
    "#last_log = epoch"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ymx-6UEQjMB"
   },
   "source": [
    "Show holograms"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "kcfzKFZuPVjQ"
   },
   "source": [
    "plt.imshow(out_hol_amp.numpy()[200:400, 100:300], \"gray\")\n",
    "plt.show()\n",
    "plt.imshow(hologram_amp.numpy()[200:400, 100:300], \"gray\")\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "agrl25wDQf2V"
   },
   "source": [
    "Save Holograms"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "UecsG8tzPEAX"
   },
   "source": [
    "out_ph = np.uint8((out_hol_amp / np.max(out_hol_amp)) * 255)\n",
    "out_ph = Image.fromarray(out_ph)\n",
    "out_ph = out_ph.convert('L')\n",
    "out_ph.save(os.path.join(log_root, 'exports', 'hologram_out.png'))\n",
    "\n",
    "out_ph = np.uint8((hologram_amp / np.max(hologram_amp)) * 255)\n",
    "out_ph = Image.fromarray(out_ph)\n",
    "out_ph = out_ph.convert('L')\n",
    "out_ph.save(os.path.join(log_root, 'exports', 'hologram_in.png'))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-iVrQg_8S6eT"
   },
   "source": [
    "'''\n",
    "in_amp = amp.copy()\n",
    "in_amp /= 1.1\n",
    "in_amp = np.uint8(in_amp * 255)\n",
    "in_amp = Image.fromarray(in_amp)\n",
    "in_amp = in_amp.convert('L')\n",
    "in_amp.save(os.path.join(log_root, 'in_amp.png'))\n",
    "\n",
    "cmap = matplotlib.cm.get_cmap('viridis')\n",
    "in_ph = (ph.copy() + np.pi)/(2*np.pi)\n",
    "in_ph = cmap(in_ph / 1.1)\n",
    "in_ph = np.uint8(in_ph * 255)\n",
    "in_ph = Image.fromarray(in_ph)\n",
    "in_ph = in_ph.convert('RGB')\n",
    "in_ph.save(os.path.join(log_root, 'in_ph.png'))\n",
    "'''\n",
    "out = model2(input_t)\n",
    "out = tf.squeeze(out)\n",
    "\n",
    "_ph = out[...,0].numpy()\n",
    "_amp = out[...,1].numpy()\n",
    "\n",
    "out_ph = np.uint8(_ph * 255)\n",
    "out_ph = Image.fromarray(out_ph)\n",
    "out_ph = out_ph.convert('L')\n",
    "out_ph.save(os.path.join(log_root, 'out_phase.png'))\n",
    "\n",
    "cmap = matplotlib.cm.get_cmap('viridis')\n",
    "out_ph = cmap(_ph.copy())\n",
    "out_ph = np.uint8(out_ph * 255)\n",
    "out_ph = Image.fromarray(out_ph)\n",
    "out_ph = out_ph.convert('RGB')\n",
    "out_ph.save(os.path.join(log_root, 'out_phase_c.png'))\n",
    "\n",
    "out_amp = np.uint8(_amp * 255)\n",
    "out_amp = Image.fromarray(out_amp)\n",
    "out_amp = out_amp.convert('L')\n",
    "out_amp.save(os.path.join(log_root, 'out_amp.png'))\n",
    "'''\n",
    "scale = 0\n",
    "out_amp = _amp * 1.1\n",
    "out_amp = scale + out_amp * (1-scale)\n",
    "out_amp /= 1.1\n",
    "out_amp = np.uint8(_amp * 255)\n",
    "out_amp = Image.fromarray(out_amp)\n",
    "out_amp = out_amp.convert('L')\n",
    "out_amp.save(os.path.join(log_root, 'out_amp_scale.png'))\n",
    "'''\n",
    "with open(os.path.join(log_root, \"details.txt\"), \"w\") as text_file:\n",
    "  text = \"Epochs: {:d}\".format(cached_epochs)\n",
    "  text += \"\\nFinal loss avg: {:.3f}\".format(loss_avg)\n",
    "  text += \"\\nLearning rate: {:.4f}\".format(lr)\n",
    "  text += \"\\nWeight decay: {:.4f}\".format(weight_decay)\n",
    "  text += \"\\n\"\n",
    "  text += \"\\nRandom initializer: \" + str(random_init)\n",
    "  text += \"\\nRandom amplitude: \" + str(random_amp)\n",
    "  text += \"\\nRandom phase: \" + str(random_ph)\n",
    "  text += \"\\n\"\n",
    "  text += \"\\nInitializer coef: {:.3f}\".format(rand_init_coef)\n",
    "  text += \"\\nAmplitude coefs: \" + ', '.join(['{:.2f}'.format(c) for c in amp_coefs])\n",
    "  text += \"\\nPhase coef: {:.3f}\".format(ph_coef)\n",
    "  text += \"\\n\"\n",
    "  text += \"\\nPhase minimum: {:.4f}\".format(np.min(_ph))\n",
    "  text += \"\\nPhase maximum: {:.4f}\".format(np.max(_ph))\n",
    "  text += \"\\nAmp minimum: {:.4f}\".format(np.min(_amp))\n",
    "  text += \"\\nAmp maximum: {:.4f}\".format(np.max(_amp))\n",
    "\n",
    "  print(text, file=text_file)\n",
    "\n",
    "plt.imshow(_ph, vmin=0, vmax=1)\n",
    "plt.show()\n",
    "plt.imshow(_amp, vmin=0, vmax=1, cmap='gray')\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}