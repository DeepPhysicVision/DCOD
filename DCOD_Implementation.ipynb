{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Deep Compressive Object Decoder (DCOD)\n",
    "Implementation and proof of work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from network import deep_decoder\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers as ls, activations as acts\n",
    "import tensorflow_addons as tfa\n",
    "from skimage.restoration import unwrap_phase\n",
    "from fringe.utils.io import import_image, export_image\n",
    "from fringe.utils.modifiers import ImageToArray, PreprocessHologram, ConvertToTensor\n",
    "from fringe.process.gpu import AngularSpectrumSolver as AsSolver\n",
    "\n",
    "device = 'gpu'\n",
    "\n",
    "if device == \"gpu\":\n",
    "  if len(tf.config.experimental.list_physical_devices('GPU')) > 0:\n",
    "    print('GPU is up and running')\n",
    "    device = \"/gpu:0\"\n",
    "  else:\n",
    "    print('GPU is not available. The program will run on CPU')\n",
    "    device = \"/cpu:0\"\n",
    "elif device == \"tpu\":\n",
    "  if len(tf.config.experimental.list_physical_devices('TPU')) > 0:\n",
    "    print('TPU is up and running')\n",
    "    device = \"/tpu:0\"\n",
    "  else:\n",
    "    print('TPU is not available. The program will run on CPU')\n",
    "    device = \"/cpu:0\"\n",
    "else:\n",
    "  device = \"/cpu:0\"\n",
    "\n",
    "dtype_f = tf.float32\n",
    "dtype_c = tf.complex64"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Sample 1: Cheek Cells"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "outputs": [],
   "source": [
    "hologram_path = '/content/drive/My Drive/Colab/Dataset/Custom/cheek/2.tif'\n",
    "background_path = '/content/drive/My Drive/Colab/Dataset/Custom/background1.tif'\n",
    "\n",
    "p1 = ImageToArray(bit_depth=16, channel='gray', crop_window=[850, 1000, 512, 512], dtype='float32')\n",
    "bg = import_image(background_path, preprocessor=p1)\n",
    "p2 = PreprocessHologram(background=bg)\n",
    "p3 = ConvertToTensor(dtype=dtype_c)\n",
    "hologram = import_image(hologram_path, preprocessor=[p1, p2, p3])\n",
    "hologram_amp = tf.math.abs(hologram)\n",
    "\n",
    "solver = AsSolver(shape=hologram_amp.shape, dx=1.12, dy=1.12, wavelength=532e-3)\n",
    "z = 238\n",
    "rec = solver.solve(hologram, z)\n",
    "amp = np.abs(rec)\n",
    "#phase = unwrap_phase(np.angle(rec))\n",
    "\n",
    "plt.imshow(hologram_amp.numpy(), cmap='gray')\n",
    "plt.show()\n",
    "plt.imshow(amp, cmap='gray')\n",
    "plt.show()\n",
    "plt.hist((hologram_amp.numpy()).flatten(), 256)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Sample 2: Red Blood Cells"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hologram_path = '/content/drive/My Drive/Colab/Dataset/Custom/rbc/rbc_3.tif'\n",
    "background_path = '/content/drive/My Drive/Colab/Dataset/Custom/background1.tif'\n",
    "\n",
    "p1 = ImageToArray(bit_depth=16, channel='gray', crop_window=[1000, 1100, 512, 512], dtype='float32')\n",
    "bg = import_image(background_path, preprocessor=p1)\n",
    "p2 = PreprocessHologram(background=bg)\n",
    "p3 = ConvertToTensor(dtype=dtype_c)\n",
    "hologram = import_image(hologram_path, preprocessor=[p1, p2, p3])\n",
    "hologram_amp = tf.math.abs(hologram)\n",
    "\n",
    "solver = AsSolver(shape=hologram_amp.shape, dx=1.12, dy=1.12, wavelength=532e-3)\n",
    "z = 315\n",
    "rec = solver.solve(hologram, z)\n",
    "amp = np.abs(rec)\n",
    "#phase = unwrap_phase(np.angle(rec))\n",
    "\n",
    "plt.imshow(hologram_amp.numpy(), cmap='gray')\n",
    "plt.show()\n",
    "plt.imshow(amp, cmap='gray')\n",
    "plt.show()\n",
    "plt.hist((hologram_amp.numpy()).flatten(), 256)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Sample 3: Diffraction Grating"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ImageToArray' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-3-c1153b76a1fa>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[0mbackground_path\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m'/content/drive/My Drive/Colab/Dataset/Custom/background.tif'\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 4\u001B[1;33m \u001B[0mp1\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mImageToArray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbit_depth\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m16\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mchannel\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'gray'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcrop_window\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m900\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m170\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m512\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m512\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'float32'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      5\u001B[0m \u001B[0mbg\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mimport_image\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbackground_path\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpreprocessor\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mp1\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m*\u001B[0m \u001B[1;36m0.1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[0mp2\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mPreprocessHologram\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbackground\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mbg\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'ImageToArray' is not defined"
     ]
    }
   ],
   "source": [
    "hologram_path = '/content/drive/My Drive/Colab/Dataset/Custom/resolution/2.tif'\n",
    "background_path = '/content/drive/My Drive/Colab/Dataset/Custom/background.tif'\n",
    "\n",
    "p1 = ImageToArray(bit_depth=16, channel='gray', crop_window=[900, 170, 512, 512], dtype='float32')\n",
    "bg = import_image(background_path, preprocessor=p1) * 0.1\n",
    "p2 = PreprocessHologram(background=bg)\n",
    "p3 = ConvertToTensor(dtype=dtype_c)\n",
    "hologram = import_image(hologram_path, preprocessor=[p1, p2, p3])\n",
    "hologram_amp = tf.math.abs(hologram)\n",
    "\n",
    "solver = AsSolver(shape=hologram_amp.shape, dx=1.12, dy=1.12, wavelength=532e-3)\n",
    "z = 956\n",
    "rec = solver.solve(hologram, z)\n",
    "amp = np.abs(rec)\n",
    "#phase = unwrap_phase(np.angle(rec))\n",
    "\n",
    "plt.imshow(hologram_amp.numpy(), cmap='gray')\n",
    "plt.show()\n",
    "plt.imshow(amp, cmap='gray')\n",
    "plt.show()\n",
    "plt.hist((hologram_amp.numpy()).flatten(), 256)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Sample 4: USAF 1951"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hologram_path = '/content/drive/My Drive/Colab/Dataset/Custom/resolution/1.tif'\n",
    "background_path = '/content/drive/My Drive/Colab/Dataset/Custom/background2.tif'\n",
    "\n",
    "p1 = ImageToArray(bit_depth=16, channel='gray', crop_window=[190, 180, 512, 512], dtype='float32')\n",
    "bg = import_image(background_path, preprocessor=p1) * 0.1\n",
    "p2 = PreprocessHologram(background=bg)\n",
    "p3 = ConvertToTensor(dtype=dtype_c)\n",
    "hologram = import_image(hologram_path, preprocessor=[p1, p2, p3])\n",
    "hologram_amp = tf.math.abs(hologram)\n",
    "\n",
    "solver = AsSolver(shape=hologram_amp.shape, dx=1.12, dy=1.12, wavelength=532e-3)\n",
    "z = 1065\n",
    "rec = solver.solve(hologram, z)\n",
    "amp = np.abs(rec)\n",
    "#phase = unwrap_phase(np.angle(rec))\n",
    "\n",
    "plt.imshow(hologram_amp.numpy(), cmap='gray')\n",
    "plt.show()\n",
    "plt.imshow(amp, cmap='gray')\n",
    "plt.show()\n",
    "plt.hist((hologram_amp.numpy()).flatten(), 256)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Simulation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from skimage.filters import gaussian\n",
    "from fringe.modules.simulator import simulate_single\n",
    "from misc_functions import Scale\n",
    "\n",
    "amp_path = '/content/drive/My Drive/Colab/Dataset/Custom/tests/baboon.png'\n",
    "ph_path = '/content/drive/My Drive/Colab/Dataset/Custom/tests/peppers.png'\n",
    "\n",
    "p1 = ImageToArray(bit_depth=8, channel='gray', crop_window=None, dtype='float32')\n",
    "amplitude = import_image(background_path, preprocessor=p1)\n",
    "phase = import_image(background_path, preprocessor=p1)\n",
    "\n",
    "# Adjusting contrast\n",
    "amp = Scale(amp, perc=1, max_val=1)\n",
    "\n",
    "# Blurriness\n",
    "sigma = 0 #np.exp(3)\n",
    "amp = gaussian(amp, sigma, mode='reflect', truncate=np.round(10 * sigma) + 1)\n",
    "\n",
    "phase /= np.max(phase)\n",
    "phase *= 2 * np.pi - 0.2 * np.pi\n",
    "phase -= np.pi\n",
    "\n",
    "solver = AsSolver(shape=hologram_amp.shape, dx=1.12, dy=1.12, wavelength=532e-3)\n",
    "z = 300\n",
    "hologram = simulate_single(amplitude, phase, z, solver, export_path=None)\n",
    "hologram_amp = ConvertToTensor(dtype=dtype_c).process(np.abs(hologram))\n",
    "hologram_amp = tf.math.pow(hologram_amp, 2)\n",
    "\n",
    "plt.imshow(amp, cmap='gray', vmin=0, vmax=1)\n",
    "plt.show()\n",
    "plt.imshow(phase, cmap='viridis', vmin=0, vmax=2 * np.pi)\n",
    "plt.show()\n",
    "plt.imshow(hologram_amp.numpy(), cmap='gray')\n",
    "plt.show()\n",
    "plt.hist((hologram_amp.numpy()).flatten(), 256)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model Initialization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_epochs = 30000\n",
    "lr = tf.Variable(0.01, dtype=dtype_f)\n",
    "weight_decay = tf.Variable(0.002, dtype=dtype_f)\n",
    "\n",
    "def get_lr():\n",
    "\treturn lr.numpy()\n",
    "\n",
    "def get_wd():\n",
    "\treturn weight_decay.numpy()\n",
    "\n",
    "random_seed = 999\n",
    "print(\"Random Seed: \", random_seed)\n",
    "random.seed(random_seed)\n",
    "tf.random.set_seed(random_seed)\n",
    "\n",
    "input_t_ref = tf.random.normal([1, 16, 16, 256], mean=0, stddev=0.1, dtype=dtype_f)\n",
    "input_t = tf.Variable(input_t_ref)\n",
    "\n",
    "net = deep_decoder(input_shape=input_t[0].shape,\n",
    "\t\t\t\t\t layers_channels=[256, 256, 256, 256, 256],\n",
    "\t\t\t\t\t kernel_sizes=[1]*5,\n",
    "\t\t\t\t\t out_channels=2,\n",
    "\t\t\t\t\t upsample_mode='bilinear',\n",
    "\t\t\t\t\t activation_func=ls.ReLU(),\n",
    "\t\t\t\t\t out_activation=acts.sigmoid,\n",
    "\t\t\t\t\t bn_affine=True)\n",
    "\n",
    "#################################\n",
    "\n",
    "optimizer = tfa.optimizers.AdamW(learning_rate=get_lr, weight_decay=get_wd)\n",
    "mse = tf.keras.losses.MeanSquaredError()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "net.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Log Settings and Recall"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "logs_path = '/content/drive/My Drive/Colab/Logs'\n",
    "log_folder = 'log_107_cheekcells_AdamWR_ddn'\n",
    "\n",
    "log_root = os.path.join(logs_path, log_folder)\n",
    "if not os.path.exists(log_root):\n",
    "    os.mkdir(log_root)\n",
    "\n",
    "if not os.path.exists(os.path.join(log_root, 'exports')):\n",
    "    os.mkdir(os.path.join(log_root, 'exports'))\n",
    "\n",
    "#amp_coefs = [1.2, 1.1, 1.2, 1.1, 1.2, 1.1, 1.15, 1.1, 1.15, 1.1]\n",
    "amp_coefs = [1.3, 1.4]\n",
    "amp_coef = tf.Variable(amp_coefs[0], dtype=dtype_f)\n",
    "amp_rand_std = tf.Variable(0.02, dtype=dtype_f)\n",
    "\n",
    "checkpoint_folder = 'ckpts'\n",
    "checkpoint = tf.train.Checkpoint(step=tf.Variable(0),\n",
    "                                 optimizer=optimizer,\n",
    "                                 model=net,\n",
    "                                 input_t=input_t,\n",
    "                                 amp_coef=amp_coef,\n",
    "                                 amp_rand_std=amp_rand_std,\n",
    "                                 lr=lr,\n",
    "                                 wd=weight_decay)\n",
    "manager = tf.train.CheckpointManager(checkpoint, os.path.join(log_root, checkpoint_folder), max_to_keep=20)\n",
    "checkpoint.restore(manager.latest_checkpoint)\n",
    "\n",
    "save_interval = 5000\n",
    "amp_coefs_interval = 500\n",
    "last_log = int(checkpoint.step)\n",
    "start_epoch = int(checkpoint.step)\n",
    "\n",
    "if checkpoint.step.numpy() != 0:\n",
    "    print('Continuing training from step:', checkpoint.step.numpy())\n",
    "else:\n",
    "    print('Initializing model checkpoints')\n",
    "\n",
    "log_array = np.zeros((save_interval, 3), dtype='float32')\n",
    "\n",
    "log_name = 'log.csv'\n",
    "if os.path.exists(os.path.join(log_root, log_name)):\n",
    "    log = pd.read_csv(os.path.join(log_root, log_name), index_col=0)\n",
    "    log.drop(log.index[int(checkpoint.step):], inplace=True)\n",
    "    loss_list = log['loss'].tolist()[-100:]\n",
    "else:\n",
    "    log = pd.DataFrame(columns=['epoch', 'loss', 'loss_avg'], )\n",
    "    loss_list = []\n",
    "\n",
    "if int(checkpoint.step) >= save_interval-1:\n",
    "    print('\\nparameters:')\n",
    "    print('- learning rate:', checkpoint.lr.numpy())\n",
    "    print('- weight decay:', checkpoint.wd.numpy())\n",
    "    print('- amp coefficient:', checkpoint.amp_coef.numpy())\n",
    "\n",
    "    plt.plot(log['loss_avg'])\n",
    "    plt.yscale('log')\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Optimization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "random_init = True\n",
    "random_amp = True\n",
    "''''''\n",
    "lr.assign(0.01)\n",
    "weight_decay.assign(0.002)\n",
    "amp_rand_std.assign(0.02)\n",
    "amp_coefs = [1.3, 1.4]\n",
    "amp_coefs_interval = 500\n",
    "num_epochs = 30000\n",
    "trainable_variables = net.trainable_variables\n",
    "cmap = matplotlib.cm.get_cmap('viridis')\n",
    "\n",
    "for epoch in range(int(checkpoint.step), num_epochs):\n",
    "    with tf.device(device):\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "\n",
    "            if (random_init or random_amp) and epoch % amp_coefs_interval == 0 and epoch != start_epoch:\n",
    "                print(\"Randomizing on step: {}\".format(epoch))\n",
    "\n",
    "                if random_init:\n",
    "                    input_t.assign(input_t_ref + tf.random.normal(input_t_ref.shape, mean=0, stddev=amp_rand_std.numpy(), dtype=dtype_f))\n",
    "                    print(\"Adding noise to the initiallizer\")\n",
    "\n",
    "                if random_amp:\n",
    "                    amp_coef_idx = (epoch % (len(amp_coefs) * amp_coefs_interval)) // amp_coefs_interval\n",
    "                    amp_coef.assign(amp_coefs[amp_coef_idx])\n",
    "                    print(\"New amp coef: \", amp_coef.numpy())\n",
    "\n",
    "            out = net(input_t, training=True)\n",
    "            out = tf.squeeze(out)\n",
    "\n",
    "            out_ph = out[...,0]\n",
    "            out_ph = tf.scalar_mul(2 * np.pi, out_ph)\n",
    "            out_ph = tf.complex(real=tf.zeros_like(out_ph), imag=out_ph)\n",
    "            out_amp = out[...,1]\n",
    "            out_amp = tf.scalar_mul(amp_coef, out_amp)\n",
    "\n",
    "            out_amp = tf.complex(real=out_amp, imag=tf.zeros_like(out_amp))\n",
    "            out_func = tf.multiply(out_amp, tf.math.exp(out_ph))\n",
    "\n",
    "            out_hol = solver.solve(out_func, z)\n",
    "            out_hol_amp = tf.math.pow(tf.math.abs(out_hol), 2)\n",
    "\n",
    "            loss_value = mse(out_hol_amp, hologram_amp)\n",
    "\n",
    "            loss_list.append(loss_value.numpy())\n",
    "            if len(loss_list) > 100:\n",
    "                loss_list.pop(0)\n",
    "            loss_avg = np.mean(np.array(loss_list))\n",
    "\n",
    "        grads = tape.gradient(loss_value, trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, trainable_variables))\n",
    "\n",
    "        if epoch % 20 == 0:\n",
    "            print(\"Epoch {:03d}: Loss: {:.5f} Loss Avg: {:.5f}\".format(epoch, loss_value, loss_avg))\n",
    "        if epoch % 100 == 0:\n",
    "            plt.imshow(out[...,0].numpy())\n",
    "            plt.show()\n",
    "            plt.imshow(out[...,1].numpy())\n",
    "            plt.show()\n",
    "\n",
    "        if (epoch + 1) % save_interval == 0 and epoch != start_epoch:\n",
    "            #export_images(net, input_t, directory=os.path.join(log_root, 'exports'), step=int(checkpoint.step))\n",
    "            export_image(out[...,0].numpy(), path=os.path.join(log_root, 'exports', 'out_phase_{:d}.png'.format(int(checkpoint.step))),dtype='uint8')\n",
    "            export_image(cmap(out[...,0].numpy()), path=os.path.join(log_root, 'exports', 'out_phase_c_{:d}.png'.format(int(checkpoint.step))), dtype='uint8')\n",
    "            export_image(out[...,1].numpy(), path=os.path.join(log_root, 'exports', 'out_amp_{:d}.png'.format(int(checkpoint.step))), dtype='uint8')\n",
    "\n",
    "            save_path = manager.save()\n",
    "            print(\"Saved checkpoint for step: {}\".format(epoch))\n",
    "\n",
    "        if (epoch % save_interval == 0 and epoch != start_epoch) or epoch == num_epochs - 1:\n",
    "            save_path = manager.save()\n",
    "            print(\"Saved checkpoint for step: {}\".format(epoch))\n",
    "            log_array = log_array[log_array[:,1] != 0, :]\n",
    "            log = pd.concat([log, pd.DataFrame(log_array, columns=['epoch', 'loss', 'loss_avg'])], sort=False, axis=0, ignore_index=True)\n",
    "            log.to_csv(os.path.join(log_root, log_name), header=True, columns=['epoch', 'loss', 'loss_avg'])\n",
    "            log_array = np.zeros((save_interval, 3), dtype='float32')\n",
    "            last_log = epoch\n",
    "\n",
    "        log_array[epoch - last_log] = [epoch, loss_value.numpy(), loss_avg]\n",
    "\n",
    "        checkpoint.step.assign_add(1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Export holograms"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "export_image(out_hol_amp / np.max(out_hol_amp), path=os.path.join(log_root, 'exports', 'hologram_out.png'), dtype='uint8')\n",
    "export_image(hologram_amp / np.max(hologram_amp), path=os.path.join(log_root, 'exports', 'hologram_in.png'), dtype='uint8')\n",
    "\n",
    "plt.imshow(out_hol_amp.numpy(), \"gray\")\n",
    "plt.show()\n",
    "plt.imshow(hologram_amp.numpy(), \"gray\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}